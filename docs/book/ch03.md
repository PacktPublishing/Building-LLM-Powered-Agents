# Chapter 3: Cognitive Foundations

Creating an AI agent with genuine cognitive capabilities requires more than just adding features to a basic conversational system. We need to develop fundamental mechanisms for memory, reasoning, planning, and self-awareness that work together cohesively. While this might sound daunting, our cognitive workspace approach makes it surprisingly approachable.

In this chapter, we'll transform Winston from a simple conversational agent into a cognitive system with real understanding and learning abilities. We'll build on the foundation established in Chapter 2, introducing a unified architecture that enables sophisticated cognitive capabilities while maintaining implementation clarity and debuggability.

We'll begin by exploring Winston's cognitive architecture and its central workspace concept. Then we'll progressively add core cognitive capabilities: memory for maintaining context, reasoning for analyzing situations, planning for organizing actions, and meta-cognition for self-improvement. Throughout this process, we'll maintain architectural consistency while enabling increasingly sophisticated behaviors.

By the end of this chapter, you'll have evolved Winston into an agent with genuine cognitive capabilities - able to remember, reason, plan, and learn from experience. More importantly, you'll understand how these capabilities emerge naturally from our unified workspace approach. This understanding will prove invaluable as we develop even more advanced cognitive abilities in subsequent chapters.

In this chapter we're going to cover the following main topics:

- Implementing Winston's cognitive architecture and workspace system
- Building memory and attention through cognitive workspaces
- Developing reasoning capabilities through cognitive reflection
- Creating planning abilities through workspace orchestration
- Enabling multi-modal processing through unified representation
- Implementing meta-cognition through workspace monitoring

## Winston's cognitive architecture

The cognitive architecture developed in this chapter centers on a fundamental insight: modern language models excel at working with natural language descriptions and markdown-formatted text. Rather than imposing rigid structures or formal representations, we leverage these strengths through a unified cognitive workspace that serves as the foundation for memory, reasoning, planning, and meta-cognitive capabilities.

![Figure 3.1: Winston Cognitive Architecture](assets/figure_03_01.svg)

At the core of Winston's architecture lies the cognitive workspace - a markdown document that maintains the agent's mental state. This workspace provides sections for different aspects of cognition: user preferences, recent interactions, current context, and working memory. The WorkspaceManager handles persistence and updates of this workspace, allowing Winston to maintain context across sessions while keeping the implementation clean and debuggable.

Memory in this architecture emerges naturally from the workspace structure. Rather than building complex knowledge graphs or traditional databases, Winston maintains memories as markdown-formatted text that can be easily updated and referenced. This approach allows for flexible organization while working with rather than against the language model's natural capabilities for understanding and manipulating text.

Reasoning capabilities build upon this foundation through cognitive reflection. When Winston needs to analyze a situation, it creates explicit reasoning chains within the workspace, developing and refining thoughts through iteration. This process mirrors how humans often write out their thoughts to develop understanding, allowing Winston to break down complex problems and build sophisticated analyses while maintaining architectural simplicity.

Planning extends these capabilities into the future through workspace orchestration. Plans exist as structured markdown sections that track goals, steps, dependencies, and progress. This representation allows Winston to naturally modify plans as circumstances change, maintaining both the original intent and execution history. The integration with memory and reasoning enables plans to adapt based on past experiences and ongoing analysis.

Multi-modal processing maintains consistency with this approach by transforming different input types into descriptive representations within the workspace. Visual information, for example, becomes detailed textual descriptions that integrate naturally with other cognitive processes. This unified representation enables Winston to reason about and connect information from different modes without maintaining separate processing pipelines.

Meta-cognitive capabilities emerge through workspace monitoring. Winston maintains observations about its own performance and effectiveness as part of the workspace, allowing it to analyze and improve its behavior over time. This self-reflection creates a feedback loop where meta-cognitive insights influence future actions, enabling progressive refinement of cognitive strategies.

The power of this architecture lies in its unified nature, drawing inspiration from Marvin Minsky's Society of Mind theory (Minsky, 1986). Rather than implementing cognitive capabilities as a monolithic system, we've developed specialized agents - `MemoryWinston`, `ReasoningWinston`, `PlanningWinston`, and `MultimodalWinston` - each focused on specific aspects of cognition. These specialists interact through the shared workspace, creating a "society" of cognitive agents that collectively produce emergent sophisticated behaviors.

This Society of Mind approach offers several advantages. Each specialist can focus on its core capabilities - memory for maintaining context, reasoning for analysis, planning for future actions, and multimodal processing for handling different types of input. Yet through the shared workspace, these specialists maintain awareness of each other's insights and contributions, enabling natural collaboration and integration. The markdown format ensures human readability and easy debugging, while the consistent representation simplifies both specialist development and inter-specialist communication.

The architecture's strength comes from balancing specialization with integration. Each cognitive capability maintains its focus and clarity while contributing to the collective intelligence of the system. This approach aligns with both Minsky's theoretical framework and practical engineering considerations, creating a robust foundation for developing increasingly sophisticated AI behaviors.

This architecture might appear simple compared to traditional AI systems with their complex knowledge representations and formal reasoning engines. However, its strength comes from working with language model capabilities rather than forcing them into rigid structures. The cognitive workspace provides a foundation that supports both current functionality and future enhancement while remaining comprehensible and maintainable.

As we build more advanced capabilities in subsequent chapters, this architecture will prove its value. The workspace format accommodates increasingly sophisticated representations while maintaining backward compatibility. New cognitive capabilities integrate naturally through the shared workspace. The meta-cognitive layer enables continuous improvement through experience. These characteristics create a robust foundation for developing truly intelligent agent behaviors.

## Basic memory & attention through cognitive workspaces

The transition from a simple conversational agent to one with genuine cognitive capabilities requires careful consideration of how to represent and manage mental state. While traditional approaches often rely on structured databases or complex knowledge graphs, we've found that working with large language models demands a different paradigm. These models excel at understanding and manipulating natural language, suggesting an alternative approach that leverages their inherent capabilities rather than forcing them into rigid structures.

Our solution emerges from two key insights about modern language models. First, they demonstrate remarkable ability to work with markdown-formatted text, parsing and understanding both structure and content with high fidelity. Second, they excel at maintaining and updating context when that context is presented as a coherent document rather than fragmented data points. These observations led us to develop cognitive workspaces - markdown documents that serve as dynamic scratchpads for agent memory and attention.

Consider how human experts often work: they maintain notes, organize thoughts in documents, and use whiteboards to track context and develop ideas. Our cognitive workspace approach mirrors this natural process, providing agents with similar tools for managing their mental state. This approach offers several advantages over more traditional structured storage. It maintains flexibility while providing light organization through markdown's natural hierarchy. It remains human-readable and easily debuggable. Perhaps most importantly, it works with rather than against the language model's natural capabilities.

The core system provides workspace management capabilities through the `WorkspaceManager` singleton class, which handles the persistence and manipulation of cognitive workspaces. This separation of concerns allows agents to focus on cognitive processing while the system manages the underlying workspace mechanics. The implementation supports both private workspaces for individual agents and shared workspaces for collaborative cognition. The workspace manager also allows customization of the initial workspace structure through templates, enabling different cognitive architectures to be explored while maintaining consistent management.

Let's examine the key aspects of the workspace implementation:

```python
def initialize_workspace(
  self,
  workspace_path: Path,
  content: str | None = None,
) -> None:
  """Initialize a workspace if it doesn't exist."""
  if not workspace_path.exists():
    workspace_path.parent.mkdir(parents=True, exist_ok=True)
    workspace_path.write_text(
      content or DEFAULT_INITIAL_TEMPLATE
    )
```

Where the `content` argument is a string that will be used to initialize the workspace. If no content is provided, the workspace will be initialized with a default template:

```markdown
# Cognitive Workspace

## User Preferences

## Recent Interactions

## Current Context

## Working Memory
```

The workspace manager maintains a consistent interface for workspace operations while supporting both private and shared contexts. This allows agents to maintain their own cognitive state while also participating in collaborative reasoning when needed. The template system enables experimentation with different workspace structures while maintaining the core benefits of our markdown-based approach.

The update process integrates new information while maintaining workspace coherence:

```python
async def update_workspace(
  self,
  workspace_path: Path,
  message: Message,
  agent: Agent,
  update_template: str | None = None,
) -> str:
  """Update workspace with new interaction."""
  workspace = self.load_workspace(workspace_path)

  # Base prompt template

  # Dynamic content formatting based on message type
  msg_type = message.metadata.get(
    "type", "Interaction"
  )

  content_format = (
    message.content
    if msg_type != "Interaction"
    else f"User: {message.content}"
  )

  update_prompt = dedent(
    (
      update_template or DEFAULT_UPDATE_TEMPLATE
    ).format(
      msg_type=msg_type.replace("_", " "),
      content_format=content_format,
      workspace=workspace,
    )
  ).strip()

  response = await agent.generate_response(
    Message(
      content=update_prompt,
      metadata={"type": "Workspace Update"},
    )
  )
  self.save_workspace(
    workspace_path, response.content
  )
  return response.content
```

This implementation represents our first step toward true cognitive capabilities. While simple in concept, it provides a foundation for more sophisticated memory and attention mechanisms we'll develop in later chapters. The cognitive workspace approach will prove particularly valuable as we add reasoning capabilities, as it provides a natural medium for tracking chains of thought and maintaining context across multiple reasoning steps.

The workhorse of the update operation is the prompt:

````markdown
Update the `Current Workspace` to incorporate the new information effectively.

# Steps

1. **Integrate Key Insights**: Extract critical insights and relationships from `Update Content` and integrate them into the existing workspace.
2. **Specific Updates**:
   - If `Message Type` is "Interaction": Update the relevant workspace sections, such as context and preferences.
   - For other types, create or append sections as necessary to reflect the new content appropriately (i.e., if it is new, retain all details as provided)
3. **Preserve Structure**: Maintain existing sections, formatting, and overall organization to ensure clarity and conciseness.

# Output Format

Provide the updated workspace in a clear and structured markdown format, maintaining existing layout and introducing necessary modifications or additions to incorporate new content.

# Examples

**Example 1**

- **Input**:

  - `msg_type`: "Interaction"
  - `content_format`: "User interacted with new features."
  - `workspace`: "## Existing Context..."

- **Output**:
  - `workspace`: "## Existing Context... \n\n### Updated Features...\n- User interacted with new features...\n"

(Note: realistic examples should include detailed content and integration reflecting the actual updates for clarity and completeness.)

Message Type: {msg_type}
Update Content:

```markdown
{content_format}
```

Current Workspace:

```markdown
{workspace}
```
````

This prompt will incorporate updates into the workspace based on the message type and content. If the message type is "Interaction", it will update the relevant sections, such as context and preferences. For other types, it will create or append sections as necessary to reflect the new content appropriately. We'll see how this works in practice in the next section.

While this straightforward approach to workspace management might raise questions about scalability with larger memory contexts or more complex cognitive states, it provides an excellent foundation for developing and understanding core cognitive capabilities. In later chapters, we'll explore various approaches to handling scale - including hierarchical memory organization, selective attention mechanisms, and memory consolidation strategies. We might also investigate techniques like semantic chunking and priority-based memory management. However, the current implementation's simplicity and transparency make it ideal for developing and debugging cognitive behaviors, and it will serve us well through many sophisticated capabilities we'll develop in upcoming chapters.

Next, let's take a look at the MemoryWinston implementation in `examples/ch03/winston_memory.py` which demonstrates how to extend the BaseAgent with workspace capabilities.

### Getting workspaces and preparing the prompt

The `process` method begins by retrieving both private and shared workspaces through the `_get_workspaces` helper. Private workspaces maintain agent-specific memories and context, while shared workspaces enable collaboration between specialist agents. This dual-workspace approach reflects Minsky's Society of Mind architecture, where individual agents maintain their own understanding while contributing to collective intelligence. The message metadata includes an optional `shared_workspace` path, signaling whether the agent operates independently or as part of a larger cognitive system. When preparing the response prompt, the method incorporates both private context and, when available, shared context to inform its reasoning.

```python:examples/ch03/winston_memory.py
async def process(
  self,
  message: Message,
) -> AsyncIterator[Response]:
  """Process message in private memory workspace."""
  private_workspace, shared_workspace = (
    self._get_workspaces(message)
  )

  shared_context = ""
  if shared_workspace:
    shared_context = f"""
    And considering the shared context:
    {shared_workspace}
    """

  # Generate initial memory-focused response
  response_prompt = f"""
  Given this message:
  {message.content}

  Using your private context:
  {private_workspace}

  {shared_context}

  Generate initial thoughts focusing on:
  1. Personal recollections and experiences
  2. Individual preferences and patterns
  3. Key memory triggers and associations
  """
```

### Generating the LLM response

Response generation streams through the language model while accumulating content for later workspace updates. The prompt structure guides the model to focus on personal recollections, individual preferences, and key memory triggers - elements that help build both private understanding and potentially relevant insights for the collective. The streaming approach allows for progressive refinement of thoughts, mirroring human cognitive processes where understanding develops through iteration. This accumulated content becomes the raw material for updating both private and shared mental models.

```python
  # Stream responses and accumulate content
  accumulated_content: list[str] = []

  async for (
    response
  ) in self.generate_streaming_response(
    Message(
      content=response_prompt,
      metadata={"type": "Memory Processing"},
    )
  ):
    accumulated_content.append(response.content)
    yield response
```

### Updating the workspaces

The final phase updates both private and shared workspaces through the `_update_workspaces` helper. This selective update mechanism represents a crucial aspect of multi-agent cognition - the ability to maintain private understanding while sharing relevant insights with the collective. The agent decides which aspects of its processing merit addition to the shared context, similar to how human experts maintain both personal knowledge and shared professional understanding. The workspace updates preserve the markdown structure while integrating new insights, maintaining cognitive continuity across both individual and collective memory spaces.

```python
  # After processing, update workspace(s)
  if not accumulated_content:
    return

  await self._update_workspaces(
    Message(
      content="".join(accumulated_content),
      metadata={
        **message.metadata,
        "type": "Memory Processing",
      },
    ),
  )
```

This implementation demonstrates how specialist agents can function both independently and as part of larger cognitive systems. The shared workspace mechanism enables sophisticated multi-agent behaviors while preserving individual agent autonomy. This balance between private and collective cognition proves particularly valuable as we develop more specialized agents in subsequent sections, each contributing unique capabilities to the overall cognitive architecture.

The dual-workspace approach creates natural opportunities for meta-cognitive development. Agents can observe how their private understanding relates to collective knowledge, enabling progressive refinement of both individual capabilities and collaborative strategies. This architectural choice supports both current functionality and future enhancement while maintaining implementation clarity and debuggability.

The cognitive workspace approach transforms Winston from a stateless chatbot into an agent with genuine memory and learning capabilities. Let's examine how this plays out in practice through an interaction:

![Figure 3.2: Initial Interaction](assets/figure_03_02.png)
_Figure 3.2: Winston learns about the user's interests and preferences_

In this initial interaction, Winston learns about the user's commuting habits. The WorkspaceManager maintains this information in the cognitive workspace:

```markdown
# Cognitive Workspace

## User Preferences

- User prefers public transit for commuting to work.
- User enjoys reading.

## Recent Interactions

- User mentioned their commuting habits, specifically using public transit.
- User lives about a 5-minute walk from the subway station.

## Current Context

- User utilizes public transit as their primary mode of transportation to work.
- User's proximity to the subway station suggests convenience in their daily commute.

## Working Memory

- User's commuting method is noted for future reference.
- User's interest in reading is acknowledged for potential future discussions.
```

(Your version of the workspace will look different, but it will have the same structure.)

Even after completely closing and restarting the application, Winston maintains awareness of these preferences and past interactions. The WorkspaceManager handles the persistence of this information, allowing the agent to build genuine long-term understanding of each user rather than starting fresh each session.

![Figure 3.3: Persistence After Reset](assets/figure_03_03.png)
_Figure 3.3: Winston maintains context even after a complete restart_

The WorkspaceManager's design offers practical advantages beyond just maintaining context. The markdown format makes it easy to inspect and modify the cognitive workspace directly, enabling manual corrections or updates when needed. The human-readable nature of the storage also makes it straightforward to debug issues or understand how Winston's understanding evolves over time.

By incorporating workspace management into the core system, we establish a foundation that future cognitive capabilities can build upon. The WorkspaceManager provides a consistent interface for workspace operations while maintaining the flexibility that makes our approach effective. This architectural decision separates the mechanics of workspace management from the cognitive processing that agents perform, creating a cleaner and more maintainable system.

This implementation represents our first step toward true cognitive capabilities. While simple in concept, it provides a foundation for more sophisticated memory and attention mechanisms we'll develop in later chapters. The cognitive workspace approach will prove particularly valuable as we add reasoning capabilities, as it provides a natural medium for tracking chains of thought and maintaining context across multiple reasoning steps.

## Basic reasoning through cognitive reflection

The addition of memory through cognitive workspaces enables Winston to maintain context, but memory alone does not create understanding. True cognitive capabilities require the ability to analyze, interpret, and draw conclusions from stored information. Reasoning in AI systems serves the purpose of deriving conclusions from available information, understanding relationships, and making informed decisions based on those insights. It allows AI to navigate uncertainty, draw inferences, and adapt to new situations, which is distinct from planning. Planning typically involves formulating a sequence of actions to achieve a specific goal, often relying on predefined rules or algorithms. While traditional approaches to AI reasoning often involve rule engines or formal logic systems, our experience with large language models suggests an alternative approach that builds on their natural ability to develop and articulate chains of thought.

When humans engage in complex reasoning, we often write out our thoughts, review them, refine them, and build upon previous insights. This process of cognitive reflection allows us to break down complex problems, examine our assumptions, and develop sophisticated understanding through iteration. Modern language models demonstrate similar capabilities when given space to "think through" problems step by step, suggesting an approach to reasoning that extends our cognitive workspace concept.

### Message Routing Through Capability Detection

A key architectural element in our specialized agent approach is the ability to route messages to the most appropriate cognitive processor. While later chapters will explore sophisticated intent classification, our initial implementation uses a straightforward but effective trigger-based approach through the `can_handle` class method.

The reasoning agent demonstrates this pattern through explicit detection of analytical needs. When a message contains phrases like "analyze," "understand," or "explain why," the agent recognizes its relevance to the task. This capability detection serves as a routing mechanism, allowing the top-level cognitive agent to delegate messages to appropriate specialists.

Consider the reasoning agent's implementation:

```python
@classmethod
def can_handle(cls, message: Message) -> bool:
  """Check if this agent can handle the message."""
  return any(
    trigger in message.content.lower()
    for trigger in [
      "analyze",
      "understand",
      "explain why",
      "what's causing",
      "help me understand",
      "struggling with",
      "having trouble",
    ]
  )
```

This simple pattern matching represents a deliberate architectural choice. While more sophisticated intent classification systems exist, starting with explicit triggers allows us to establish and validate our basic cognitive architecture before adding complexity. The `can_handle` method provides a clean interface for capability detection that we'll enhance in later chapters.

Each specialized agent implements its own `can_handle` logic, creating a natural routing system. The planning agent looks for terms like "plan" and "organize," while the multimodal agent checks for image-related metadata. This distributed approach to capability detection maintains architectural clarity while enabling sophisticated cognitive behaviors to emerge from the interaction of specialized processors.

The provisional nature of this trigger-based approach shouldn't obscure its architectural significance. As we develop more advanced intent classification in subsequent chapters, the `can_handle` interface will remain consistent while its implementation grows more sophisticated. This evolution path demonstrates our commitment to starting simple while maintaining clear upgrade paths for future enhancement.

### The reasoning process

Building on the workspace management pattern established with the memory agent, the reasoning specialist's `process` method follows the same logical flow but with a prompt specifically crafted for analytical tasks. After verifying that the message requires reasoning through `can_handle`, the agent prepares its workspaces, generates an analytical response, and updates its cognitive state.

The key distinction lies in the analytical prompt:

```text
Analyze this situation:
{message.content}

Using your private context:
{private_workspace}

{shared_context}

Develop a comprehensive analysis that:
1. Identifies key elements and relationships
2. Draws on relevant private and shared context
3. Provides clear insights and conclusions
```

This prompt structure guides the language model to perform deep analytical processing rather than simple recall or response generation. By explicitly requesting identification of relationships and connection to context, we enable the emergence of genuine reasoning capabilities while maintaining our unified workspace approach.

The rest of the implementation follows our established pattern of streaming response generation and workspace updates, demonstrating how specialized cognitive capabilities can be developed through careful prompt engineering within our consistent architectural framework.

Consider how this plays out in practice. When a user seeks to understand any complex situation - whether it's analyzing market trends, debugging code, planning a vacation, or even deciding what to cook for dinner - Winston first determines if analysis is needed through its trigger detection. Upon recognizing an analytical need, it engages its reasoning capabilities, drawing on workspace context to develop a structured understanding. The resulting analysis becomes part of the workspace, available for future reference and refinement.

This approach to reasoning differs significantly from traditional expert systems or rule-based approaches. Rather than attempting to encode all possible analytical patterns, we leverage the language model's inherent ability to develop coherent analytical narratives. The structured prompting guides this process while maintaining flexibility to handle diverse situations.

The integration of reasoning with memory creates particularly powerful combinations. When analyzing situations, Winston can draw on both general knowledge and specific memories of past interactions. This context enriches the reasoning process, enabling more personalized and practical insights. Similarly, the conclusions from reasoning processes become part of the workspace's memory, available for future reference and refinement.

Let's see how this reasoning process works through a concrete example:

![Figure 3.4: Reasoning Process](assets/figure_03_04.png)
_Figure 3.4: Winston analyzes a user'schallenges_

In this interaction, the user is asking for advice on whether to take an umbrella today. (I seeded the `winston_reason.md` workspace with the `winston_memory.md` workspace to start.) The resulting workspace captures not just conclusions but the analytical process itself, incorporating user preferences and past experiences:

```markdown
# Cognitive Workspace

## User Preferences

- User prefers public transit for commuting to work.
- User enjoys reading.
- User values practicality and proactivity in planning daily activities.

## Recent Interactions

- User mentioned their commuting habits, specifically using public transit.
- User lives about a 5-minute walk from the subway station.
- User inquired about their typical commute to work.
- User asked for advice on whether to take an umbrella today.
- User requested an explanation regarding the necessity of an umbrella.
- User expressed a desire to manage their daily commute effectively.

## Current Context

- User utilizes public transit as their primary mode of transportation to work.
- User's proximity to the subway station suggests convenience in their daily commute.
- User's commute is likely consistent, given their established routine.
- User is considering weather conditions and their impact on daily activities.
- User is actively seeking practical advice related to weather, indicating a proactive approach to planning.
- User's potential need for an umbrella reflects their awareness of the unpredictable British weather.

## Working Memory

- User's commuting method is noted for future reference.
- User's interest in reading is acknowledged for potential future discussions.
- User's inquiry about their commute indicates a reflective consideration of their daily habits.
- User's question about the umbrella suggests a practical concern for daily weather conditions.
- User's latest interaction reflects an interest in understanding the implications of weather on their day.
- User's proactive nature indicates a preference for being prepared for unexpected situations.

## Umbrella Analysis

- **Commute Method**: Public transit (subway).
- **Distance to Subway**: 5-minute walk.
- **Weather Consideration**: Potential rain (implied necessity for an umbrella).
- **Recommendation**: Given the short walk to the subway and the convenience of public transit, taking an umbrella is advisable if rain is in the forecast. This will help maintain comfort while reading during the commute and avoid the discomfort of getting wet.

Ultimately, it's better to have it and not need it than to need it and not have it. A classic British sentiment, wouldn't you agree?
```

While this example demonstrates basic reasoning capabilities, it lays the groundwork for more sophisticated features. In future iterations, Winston will evolve beyond analysis to take concrete actions based on its reasoning - for instance, checking real-time weather data to provide more actionable umbrella advice. This implementation marks an important transition from an agent that simply recalls information to one that can analyze and understand complex situations. Though our current trigger-based approach to initiating analysis is straightforward, it provides a foundation for more sophisticated detection mechanisms we'll explore in later chapters. The success of this approach reinforces our fundamental design philosophy: working with language model strengths rather than imposing artificial constraints.

## Basic planning through workspace orchestration

Planning represents a natural evolution of reasoning capabilities. While reasoning allows Winston to analyze and understand situations, planning extends this ability into the future, organizing potential actions and tracking their execution. Our approach to planning maintains consistency with our cognitive workspace philosophy, treating plans not as rigid data structures but as living documents that evolve through interaction and reflection.

The traditional approach to AI planning often involves formal representations like PDDL (Planning Domain Definition Language) or complex hierarchical task networks. These approaches excel in domains with clear, well-defined actions and goals but prove brittle when dealing with the ambiguous, open-ended requests that characterize human interaction. Our experience with language models suggests an alternative approach: representing plans as structured narrative within the cognitive workspace.

This narrative approach to planning aligns with how humans naturally create and modify plans. Consider how we might plan a project on paper - we write out goals, break them into steps, note dependencies, and adjust our plans as circumstances change. The cognitive workspace enables Winston to work similarly, maintaining plans as markdown sections that can be readily updated and refined.

### Plan formulation

The first key capability of the planning agent is the ability to formulate structured plans from open-ended requests. This process involves analyzing goals, breaking down tasks, identifying dependencies, and anticipating challenges. The implementation uses trigger detection to recognize planning needs:

```python
@classmethod
def _needs_planning(cls, message: Message) -> bool:
  """Check if message needs planning."""
  return any(
    trigger in message.content.lower()
    for trigger in [
      "plan",
      "organize",
      "schedule",
      "steps to",
      "how should i",
      "what's the best way to",
      "help me figure out how to",
    ]
  )
```

When planning is needed, Winston engages its plan formulation capabilities through a structured prompt:

```text
Create an initial plan for:
{message.content}

Using your private context:
{private_workspace}

{shared_context}

Develop a draft plan including:
1. Initial goal analysis
2. Preliminary steps
3. Potential challenges
4. Resource requirements
```

This prompt guides the language model to create comprehensive plans that consider both immediate requirements and potential future challenges. The resulting plan becomes part of the cognitive workspace, allowing for future refinement and execution tracking.

### Plan execution

The second key capability involves executing and tracking plan steps. This process requires different cognitive skills - understanding current progress, verifying prerequisites, and adapting to real-world feedback. The implementation recognizes execution requests through specific triggers:

```python
@classmethod
def _is_execution(cls, message: Message) -> bool:
  """Check if message is execution request."""
  return any(
    trigger in message.content.lower()
    for trigger in [
      "execute",
      "start",
      "begin",
      "do",
      "implement",
      "carry out",
      "perform",
      "complete step",
    ]
  )
```

When executing plan steps, Winston uses a different prompt focused on preparation and verification:

```text
Regarding execution request:
{message.content}

Review private execution context:
{private_workspace}

{shared_context}

Prepare execution by:
1. Identifying relevant plan steps
2. Checking prerequisites
3. Noting potential issues
```

This separation of planning and execution capabilities mirrors human cognitive processes, where we often think differently about creating plans versus carrying them out. The workspace maintains both the original plan and execution progress, enabling Winston to track completion and adapt to changing circumstances.

### Future enhancements

While this implementation provides solid foundational planning capabilities, it sets the stage for more sophisticated features. In future iterations, the planning agent could:

1. Delegate analytical tasks to the reasoning agent for deeper situation analysis
2. Maintain multiple concurrent plans in the workspace
3. Develop more sophisticated progress tracking and plan adaptation mechanisms
4. Integrate with external tools and systems for real-world execution monitoring

The success of this approach demonstrates how our cognitive workspace architecture can support sophisticated planning capabilities while maintaining implementation clarity. By representing plans as structured narrative within the workspace, we enable natural interaction between planning and other cognitive processes while keeping the system extensible and debuggable.

Let's see how this plays out in practice through an example interaction:

![Figure 3.5: Planning Process](assets/figure_03_05.png)
_Figure 3.5: Winston creates a plan_

In this interaction, the user asks: "How should I get to my meeting downtown at 9am tomorrow?"

The resulting workspace captures both the plan and its context:

```markdown
# Cognitive Workspace

## User Preferences

- User prefers public transit for commuting to work.
- User enjoys reading.
- User values practicality and proactivity in planning daily activities.

## Recent Interactions

- User mentioned their commuting habits, specifically using public transit.
- User lives about a 5-minute walk from the subway station.
- User inquired about their typical commute to work.
- User asked for advice on whether to take an umbrella today.
- User requested an explanation regarding the necessity of an umbrella.
- User expressed a desire to manage their daily commute effectively.
- User inquired about getting to a meeting downtown at 9am tomorrow.
- User has outlined a detailed meeting commute plan.

## Current Context

- User utilizes public transit as their primary mode of transportation to work.
- User's proximity to the subway station suggests convenience in their daily commute.
- User's commute is likely consistent, given their established routine.
- User is considering weather conditions and their impact on daily activities.
- User is actively seeking practical advice related to weather, indicating a proactive approach to planning.
- User's potential need for an umbrella reflects their awareness of the unpredictable British weather.
- User has a meeting downtown at 9am tomorrow, suggesting an immediate need for effective route planning.
- User has a clear plan for their commute, detailing steps to ensure timely arrival.

## Working Memory

- User's commuting method is noted for future reference.
- User's interest in reading is acknowledged for potential future discussions.
- User's inquiry about their commute indicates a reflective consideration of their daily habits.
- User's question about the umbrella suggests a practical concern for daily weather conditions.
- User's latest interaction reflects an interest in understanding the implications of weather on their day.
- User's proactive nature indicates a preference for being prepared for unexpected situations.
- User's upcoming meeting adds urgency to their need for planning their route.
- User's request for directions to their meeting downtown further emphasizes their need for practical guidance.

## Meeting Commute Plan

### 1. Clear Goal Definition

To arrive at your meeting downtown by 9:00 AM tomorrow, utilizing public transit while considering potential weather conditions.

### 2. Step-by-Step Breakdown of Actions

- [ ] **Check Weather Forecast**

  - Look up the weather for tomorrow morning to assess the likelihood of rain.

- [ ] **Prepare for Commute**

  - If rain is forecasted, pack your umbrella.
  - Ensure you have your transit pass or payment method ready.

- [ ] **Leave Home**

  - Aim to leave your residence by 8:15 AM.

- [ ] **Walk to Subway Station**

  - Allocate 5 minutes for the walk.

- [ ] **Take the Subway**

  - Check the subway schedule for the next train heading downtown.
  - Board the train to ensure you arrive at your destination by 8:45 AM.

- [ ] **Arrive Downtown**
  - Exit at the nearest station to your meeting location.
  - Allow time to walk to the meeting venue.

### 3. Dependencies and Prerequisites

- Weather forecast must be checked the evening before.
- Ensure your subway pass is valid and accessible.
- Identify the exact meeting location for accurate navigation.

### 4. Success Criteria and Milestones

- **Before 8:00 AM**: All preparations completed (umbrella packed if needed, transit pass ready).
- **8:15 AM**: Depart from home.
- **8:20 AM**: Arrive at the subway station.
- **8:30 AM**: Board the subway.
- **8:45 AM**: Arrive downtown.
- **9:00 AM**: Arrive at the meeting venue.

### 5. Potential Challenges and Mitigation Strategies

- **Challenge**: Unexpected weather changes (e.g., rain).

  - **Mitigation**: Always carry an umbrella during uncertain weather.

- **Challenge**: Subway delays or cancellations.

  - **Mitigation**: Monitor real-time transit updates and have an alternate route (e.g., bus) in mind.

- **Challenge**: Getting lost downtown.
  - **Mitigation**: Use a maps app for directions to the meeting venue and familiarize yourself with the area beforehand.

---

### Notes

- It’s prudent to be early rather than risk being late, especially in a bustling downtown environment.
- Enjoy your reading during the commute! It’s a splendid way to pass the time.

## Umbrella Analysis

- **Commute Method**: Public transit (subway).
- **Distance to Subway**: 5-minute walk.
- **Weather Consideration**: Potential rain (implied necessity for an umbrella).
- **Recommendation**: Given the short walk to the subway and the convenience of public transit, taking an umbrella is advisable if rain is in the forecast. This will help maintain comfort while reading during the commute and avoid the discomfort of getting wet.

Ultimately, it's better to have it and not need it than to need it and not have it. A classic British sentiment, wouldn't you agree?
```

In our commuting scenario, the user checks and reports the weather forecast (in the future, Winston will use his tools to check the weather automatically) and then asks what to do next:

![Figure 3.6: Winston executes a plan step](assets/figure_03_06.png)
_Figure 3.6: Winston executes a plan step_

The updated workspace now includes the execution of the plan step:

```markdown
# Cognitive Workspace

...

### 2. Step-by-Step Breakdown of Actions

- [x] **Check Weather Forecast**

  - Confirmed that the weather is sunny and windy for tomorrow.

- [x] **Prepare for Commute**

  - Pack a light jacket for the wind.
  - Ensure you have your transit pass or payment method ready.
  - Given the forecast, you may opt not to bring an umbrella.

- [ ] **Leave Home**

  - Aim to leave your residence by 8:15 AM.
    ...
```

The implementation of planning capabilities transforms Winston from an agent that analyzes current situations into one that organizes and tracks future actions. The integration with the cognitive workspace ensures plans remain accessible and updatable, while structured prompting guides the creation of clear, actionable steps. This approach proves particularly valuable when handling uncertainty or partial success - rather than treating plan steps as binary outcomes, Winston maintains nuanced understanding of progress and adapts accordingly.

The combination of planning with memory and reasoning enables sophisticated behaviors. When creating or modifying plans, Winston draws on remembered preferences, past experiences, and previous analytical insights. This context enriches the planning process, leading to more personalized and practical plans. The reasoning system can examine plan progress and suggest adaptations, creating a natural flow between understanding situations and organizing responses.

Our approach to planning through workspace orchestration demonstrates the value of working with language model capabilities. By representing plans as structured narrative rather than formal constructs, we enable Winston to handle the ambiguity inherent in real-world planning while maintaining systematic organization. This foundation supports both current functionality and future enhancement while remaining comprehensible and maintainable.

## Basic multi-modal processing through unified representation

The addition of multi-modal capabilities presents unique challenges for cognitive architectures. Traditional approaches often treat different input modes as separate streams, maintaining distinct processing pipelines and data structures for each mode. This separation, while conceptually clean, creates artificial boundaries that can impede the natural integration of information from different sources. Our experience with large language models suggests an alternative approach: representing all modes of input within the unified framework of our cognitive workspace.

Modern language models demonstrate remarkable ability to understand and reason about different types of information when that information is presented in natural language form. This observation leads us to extend our cognitive workspace approach to handle multi-modal input through descriptive representation. Rather than maintaining separate structures for different modes, we represent all inputs as markdown content, using rich descriptions to capture the essential characteristics of non-textual inputs.

At the core, `src/core/vision.py` provides utilities for handling image data, including conversion of images to base64 format (`image_to_base64`) and creation of vision-model-compatible message formats (`create_vision_messages`). This encapsulation keeps the image handling logic centralized and separates the concerns of image processing from the cognitive processing.

### Image uploading in Chainlit

Chainlit's user interface supports uploading images, which it represents as `cl.Image` elements. The `AgentChat` class detects these elements and enriches the message metadata with the image path, which is then used in the `process` method (below) to update the workspace with the image description:

```python
# In AgentChat.handle_message
metadata = {"history": history}
if message.elements and len(message.elements) > 0:
  image = message.elements[0]
  if isinstance(image, cl.Image):
    metadata["image_path"] = image.path
```

### Vision processing

The multi-modal agent's capability detection focuses specifically on the presence of image data in message metadata. This straightforward approach allows the agent to recognize when visual processing is needed without requiring complex analysis of the message content itself. The `can_handle` method simply checks for the presence of an "image_path" key in the message metadata, providing a clean interface for routing messages that require visual processing.

```python
@classmethod
def can_handle(cls, message: Message) -> bool:
  """Check if this agent can handle the message."""
  return "image_path" in message.metadata
```

The processing of visual information occurs in two distinct phases, each with its own specialized prompt. The first phase focuses on pure visual observation, using the vision model to generate detailed descriptions of the image content. This initial prompt emphasizes objective observation and detailed description, ensuring that important visual elements are captured in textual form.

```python
accumulated_content: list[str] = []
async for (
  response
) in self.generate_streaming_vision_response(
  message.content,
  message.metadata["image_path"],
):
  accumulated_content.append(response.content)
  yield response
```

The second phase integrates these visual observations with the agent's existing cognitive context. The integration prompt guides the model to connect visual observations with remembered information and current context, enabling genuine multi-modal understanding. This two-phase approach ensures both detailed visual processing and meaningful integration with other cognitive processes.

```python
Given this message:
{message.content}

And the visual observation:
{accumulated_content}

Using your private context:
{private_workspace}

{shared_context}

Generate initial thoughts focusing on:
1. Personal recollections and experiences
2. Individual preferences and patterns
3. Key memory triggers and associations
```

The workspace update process maintains our unified representation approach by incorporating both the visual observations and their interpretations into the markdown structure. This integration allows future cognitive processes to reference and build upon visual information naturally, without requiring special handling or separate storage mechanisms.

Continuing from our previous transportation example, let's see how this appears in practice:

![Figure 3.7: Winston processes visual input](assets/figure_03_07.png)
_Figure 3.7: Winston processes visual input_

Here, we are asking Winston to examine a photo of Times Square and pick a spot to meet our colleague, asking him to also provide a rationale for his choice. The results have been integrated into the workspace:

```markdown
...

## Current Context

- Discussion around commuting habits and reading preferences.
- Consideration of suitable meeting locations based on user’s commuting preferences, particularly noting the advantages of Times Square.

### Updated Insight

- The user is actively seeking recommendations for meeting spots and values the reasoning behind such choices.
- Suggested meeting location: the large digital billboard area in Times Square.
  - **Reasons for this choice**:
    1. **High Visibility:** Bright lights and large ads make it a noticeable location.
    2. **Central Location:** Accessible from various directions and transit options.
    3. **Amenities:** Numerous nearby restaurants and cafes for a coffee or bite to eat.
    4. **Vibrant Atmosphere:** Energetic backdrop conducive to productive discussions.

## Working Memory

- The image shows a text-based conversation from a chat interface, discussing commuting with a friendly and inquisitive tone. It invites the user to share more about their reading habits or commute experiences.
- User is seeking advice on meeting locations, indicating a blend of professional and social considerations in their interactions.
- **Updated Insight**: Times Square is recognized as a dynamic and convenient spot for meetings, offering a vibrant atmosphere, accessibility, and networking opportunities, aligning with the user’s preferences for lively and convenient meeting settings.
- User has requested specific reasoning for meeting location choices, indicating a desire for thoughtful and contextual recommendations.
```

The power of this unified representation becomes apparent when Winston needs to reason about complex situations involving multiple modes of input. Rather than maintaining separate reasoning processes for different input types like images, audio, or sensor data, the cognitive workspace enables natural integration of all information through descriptive text representations. This approach mirrors how humans naturally combine different types of information in their thinking processes, while maintaining architectural simplicity. Visual information persists alongside other memories in the workspace, enabling Winston to reference and compare observations over time while incorporating them into its analytical processes. This success in handling multi-modal input reinforces our fundamental design philosophy: working with the language model's natural capabilities rather than imposing artificial structures.

## Basic meta-cognition through workspace monitoring

The development of memory, reasoning, planning, and multi-modal capabilities provides Winston with sophisticated cognitive tools, but true intelligence requires more than just using these capabilities - it requires understanding and improving their use. This self-awareness and self-improvement capacity, known as meta-cognition, represents a fundamental aspect of intelligent behavior. Our approach to implementing meta-cognitive capabilities builds naturally on our cognitive workspace architecture, treating Winston's own performance and behavior as subjects for analysis and optimization.

Traditional approaches to meta-cognition in AI systems often rely on explicit performance metrics and optimization algorithms. While these approaches can be effective in narrow domains, they struggle with the complexity and ambiguity of open-ended interactions. Our experience with language models suggests an alternative: using the cognitive workspace itself as a medium for self-reflection and improvement. This approach leverages the model's natural ability to analyze and reason about described behaviors and outcomes.

The implementation in `examples/ch03/winston_metacog.py` demonstrates this approach by adding a meta-cognitive layer to Winston's workspace. This layer maintains observations about Winston's own performance, effectiveness, and areas for improvement:

```markdown
## Meta-Cognitive Analysis

Performance Observations:
User engagement decreased during technical explanations.
Response time increased when accessing older memories.
Planning effectiveness improved with explicit step tracking.

Strategy Adjustments:

- Simplified technical language based on user reactions
- Implemented progressive memory loading for faster access
- Added completion indicators to plan steps

Learning Patterns:
Recent interactions show improved context maintenance.
Multi-modal integration becoming more natural.
Plan adaptation speed increasing.
```

This self-awareness emerges through active monitoring of Winston's interactions and their outcomes. Rather than relying on external metrics, Winston maintains its own observations about its performance and effectiveness:

```python
async def monitor_interaction(self, interaction: dict) -> None:
    workspace = self.load_workspace()

    reflection_prompt = f"""
    Analyze this interaction:
    {interaction}

    Consider:
    - User engagement and satisfaction
    - Response relevance and clarity
    - Memory and context utilization
    - Reasoning and planning effectiveness

    Update the Meta-Cognitive Analysis section, maintaining existing insights
    while adding new observations and adjusting strategies as needed.
    """

    reflection = await self.generate_response(reflection_prompt)
    workspace.update_section("Meta-Cognitive Analysis", reflection.content)
    self.save_workspace(workspace)
```

The power of this approach lies in its integration with the existing cognitive architecture. Meta-cognitive observations become part of the same workspace that stores memories and plans, allowing Winston to reference and consider these insights during regular operations. This creates a feedback loop where meta-cognitive awareness influences behavior, and behavioral outcomes inform meta-cognitive understanding.

The meta-cognitive layer proves particularly valuable when Winston encounters challenges or suboptimal outcomes. Rather than simply noting failures, Winston can analyze the underlying causes and develop strategies for improvement:

```python
async def analyze_difficulty(self, context: str) -> None:
    workspace = self.load_workspace()

    analysis_prompt = f"""
    Regarding this challenging situation:
    {context}

    Review relevant workspace sections, including Meta-Cognitive Analysis.
    Identify patterns or similar past challenges.
    Consider current strategies and their effectiveness.
    Propose potential adjustments or new approaches.

    Update the workspace to reflect this analysis and any strategy changes.
    """
```

This self-reflective process enables Winston to evolve its behavior based on experience. When certain approaches prove ineffective, Winston can identify patterns and adjust its strategies accordingly. The workspace format allows these adjustments to persist across sessions, enabling long-term learning and improvement.

The integration of meta-cognition with other cognitive capabilities creates particularly powerful synergies. Meta-cognitive insights inform memory organization, guiding decisions about what information to prioritize and how to structure it for optimal access. They influence reasoning processes by highlighting successful analytical patterns and identifying areas where additional consideration might be needed. Planning benefits from meta-cognitive awareness of past plan successes and failures, enabling more effective strategy selection.

Our approach to meta-cognition through workspace monitoring demonstrates the extensibility of our cognitive workspace architecture. By representing meta-cognitive insights in the same markdown format as other cognitive processes, we maintain architectural simplicity while enabling sophisticated self-awareness and improvement capabilities. This foundation will prove valuable as we develop more advanced meta-cognitive capabilities in later chapters, including learning optimization and strategy innovation.

The success of this approach reinforces our fundamental design philosophy of working with language model strengths. By representing meta-cognitive processes as natural language analysis within the workspace, we enable Winston to develop genuine self-awareness and improvement capabilities while maintaining the benefits of our unified architectural approach.

[A diagram showing the meta-cognitive feedback loop would be valuable here. The diagram should illustrate how workspace monitoring leads to strategy adjustments, which influence behavior, which generates new observations for monitoring. The circular nature of this process, all mediated through the workspace, would help readers understand the integrated nature of the meta-cognitive system.]

This implementation of meta-cognition completes our basic cognitive architecture while setting the stage for more sophisticated capabilities. The ability to monitor and improve its own performance transforms Winston from a system that simply uses cognitive capabilities into one that actively develops and refines them through experience.

## Bringing it all together: A unified cognitive architecture

The cognitive architecture developed in this chapter centers on Minsky's Society of Mind theory, where intelligence emerges from the interaction of many specialized agents. Rather than building a monolithic agent, we create a system of specialists coordinated through a shared cognitive workspace. This approach leverages both the strengths of modern language models and insights from cognitive science about how intelligence emerges from specialized components working together.

At the core of Winston's architecture lies the CognitiveWinston class, which manages a society of specialist agents: MemoryWinston for maintaining context and experiences, ReasoningWinston for analytical tasks, PlanningWinston for organizing future actions, and MultimodalWinston for processing visual information. Each specialist maintains its own private workspace while sharing insights through a common workspace, enabling both individual expertise and collective intelligence.

Here's how the implementation in `winston_cognitive.py` orchestrates these specialists:

```python
class CognitiveWinston(BaseAgent):
    """Winston with comprehensive cognitive capabilities."""

    def __init__(
        self,
        system: System,
        config: AgentConfig,
        paths: AgentPaths,
    ) -> None:
        # Register self first
        super().__init__(system, config, paths)

        # Initialize sub-agents with their own configs
        memory_config = AgentConfig.from_yaml(
            paths.config / "agents/winston_memory.yaml"
        )
        reasoning_config = AgentConfig.from_yaml(
            paths.config / "agents/winston_reason.yaml"
        )
        planning_config = AgentConfig.from_yaml(
            paths.config / "agents/winston_plan.yaml"
        )
        multimodal_config = AgentConfig.from_yaml(
            paths.config / "agents/winston_multimodal.yaml"
        )

        # Initialize specialist agents
        self.memory_agent = MemoryWinston(
            system, memory_config, paths
        )
        self.reasoning_agent = ReasoningWinston(
            system, reasoning_config, paths
        )
        self.planning_agent = PlanningWinston(
            system, planning_config, paths
        )
        self.multimodal_agent = MultimodalWinston(
            system, multimodal_config, paths
        )
```

The process method demonstrates how Winston routes messages to appropriate specialists while maintaining shared context:

```python
async def process(
  self,
  message: Message,
) -> AsyncIterator[Response]:
  """Process incoming messages through specialist agents."""

  # Create message with shared workspace reference
  sub_message = Message(
    content=message.content,
    metadata={
      **message.metadata,
      "shared_workspace": self.workspace_path,
    },
  )

  # Route to appropriate specialist
  if self.multimodal_agent.can_handle(message):
    agent = self.multimodal_agent
  elif self.reasoning_agent.can_handle(message):
    agent = self.reasoning_agent
  elif self.planning_agent.can_handle(message):
    agent = self.planning_agent
  else:
    agent = self.memory_agent

  # Process with selected specialist
  async for response in agent.process(sub_message):
    yield response
```

This implementation reflects Minsky's vision of mind as a society of specialized agents working together. Each specialist contributes its unique capabilities while maintaining awareness of the collective context through the shared workspace. The memory specialist builds understanding of user preferences and patterns. The reasoning specialist analyzes situations and draws conclusions. The planning specialist organizes future actions. The multimodal specialist processes visual information and integrates it with existing knowledge.

The power of this approach emerges from the interactions between specialists. When analyzing a photo of a user's workspace, for instance, the multimodal specialist might recognize key elements, while the memory specialist recalls relevant preferences, the reasoning specialist draws conclusions about work habits, and the planning specialist suggests improvements. All these insights flow through the shared workspace, enabling sophisticated collective intelligence while maintaining architectural clarity.

This Society of Mind architecture proves particularly valuable for meta-cognitive development. By observing how different specialists contribute to understanding and problem-solving, Winston can progressively refine its routing and integration strategies. The shared workspace provides a natural medium for this meta-cognitive awareness, allowing Winston to improve both individual specialist capabilities and their collective interaction.

The success of this approach demonstrates how cognitive architectures can balance specialization with integration. Rather than forcing all capabilities into a monolithic system, we enable natural emergence of sophisticated behaviors through the interaction of focused specialists. This aligns with both cognitive science research and practical engineering considerations, creating a robust foundation for developing increasingly sophisticated AI capabilities.
